<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Jacob Springer | Academic Profile</title>
  <!-- Link to external CSS -->
  <link rel="stylesheet" href="style.css">
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700&display=swap" rel="stylesheet">
</head>
<body>
  <div class="container">
    <!-- Profile Section -->
    <header class="profile-header">
      <h1><a href="https://sprin.xyz/">Jacob Springer</a></h1>
      <img src="jacob.png" alt="Jacob Springer" class="profile-picture">
      <div class="profile-links">
        <a href="cv.pdf" target="_blank">CV</a>
        <a href="https://scholar.google.com/citations?user=niZiN38AAAAJ" target="_blank">Google Scholar</a>
        <a href="https://github.com/jakespringer" target="_blank">GitHub</a>
        <span>Email: jspringer@cmu.edu</span>
      </div>
    </header>

    <!-- About Section -->
    <section class="about-section">
      <h2>About</h2>
      <p>
        Hello! I am a PhD student in the Machine Learning department at Carnegie Mellon University where I am fortunate to be advised by 
        <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a>.
      </p>
      <p>
        I'm excited about solving mysteries in machine learning. I have recently been thinking about how to train models that are <i>adaptable</i>, i.e., easily and robustly fine-tuned to perform new tasks--and especially how optimization can influence this. I am broadly excited about understanding structure of what is learned by neural networks. In the past, I have also spent a lot of time thinking about (adversarial) robustness in neural networks and how we can take insights from neuroscience to improve upon machine learning. Previously, I was an undergrad at Swarthmore College, and I have spent time at Cold Spring Harbor Laboratory, MIT, and Los Alamos National Laboratory, where I worked with many lovely people. Please reach out if you want to chat about anything (I do love talking about research)!
      </p>
    </section>

    <!-- Publications Section -->
    <section class="publications">
      <h2>Selected Publications (<a href="https://scholar.google.com/citations?user=niZiN38AAAAJ" target="_blank">more</a>)</h2>
      <ol>
        <!-- 2024 -->
        <li>
          <strong>2024</strong> – “<a href="https://arxiv.org/abs/2402.15449" target="_blank">Repetition improves language model embeddings</a>”
          <br>
          <em>Springer, Jacob Mitchell; Kotha, Suhas; Fried, Daniel; Neubig, Graham; Raghunathan, Aditi</em>
          <br>
          <small>Preprint.</small>
        </li>
        <li>
          <strong>2024</strong> – “<a href="https://arxiv.org/abs/2405.20439" target="_blank">Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning</a>”
          <br>
          <em>Springer, Jacob Mitchell; Nagarajan, Vaishnavh; Raghunathan, Aditi</em>
          <br>
          <small>International Conference on Learning Representations (2024)</small>
        </li>
        <!-- 2023 -->
        <li>
          <strong>2024</strong> – “<a href="https://arxiv.org/abs/2309.10105" target="_blank">Understanding catastrophic forgetting in language models via implicit inference</a>”
          <br>
          <em>Kotha, Suhas; Springer, Jacob Mitchell; Raghunathan, Aditi</em>
          <br>
          <small>International Conference on Learning Representations (2024)</small>
        </li>
        <!-- 2022 -->
        <li>
          <strong>2022</strong> – “If you’ve trained one you’ve trained them all: inter-architecture similarity increases with robustness” <b>(Oral)</b>
          <br>
          <em>Jones, Haydn T; Springer, Jacob M; Kenyon, Garrett T; Moore, Juston S</em>
          <br>
          <small>Uncertainty in Artificial Intelligence (2022)</small>
        </li>
        <!-- 2021 -->
        <li>
          <strong>2021</strong> – “<a href="https://sprin.xyz/" target="_blank">It's hard for neural networks to learn the game of life</a>”
          <br>
          <em>Springer, Jacob M; Kenyon, Garrett T</em>
          <br>
          <small>International Joint Conference on Neural Networks (2021)</small>
        </li>
        <li>
          <strong>2021</strong> – “<a href="https://arxiv.org/abs/2106.02105" target="_blank">A little robustness goes a long way: Leveraging robust features for targeted transfer attacks</a>”
          <br>
          <em>Springer, Jacob; Mitchell, Melanie; Kenyon, Garrett</em>
          <br>
          <small>Advances in Neural Information Processing Systems (2021)</small>
        </li>
        <li>
          <strong>2021</strong> – “<a href="https://arxiv.org/abs/2102.05110" target="_blank">Adversarial perturbations are not so weird: Entanglement of robust and non-robust features in neural network classifiers</a>”
          <br>
          <em>Springer, Jacob M; Mitchell, Melanie; Kenyon, Garrett T</em>
          <br>
          <small>Preprint.</small>
        </li>
        <!-- 2020 -->
      </ol>
    </section>
    <footer>
    </footer>
  </div>
</body>
</html>

